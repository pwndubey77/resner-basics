{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4B.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7Im7q4FkY_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "2af5c959-310a-48f4-e529-542821579c5f"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jui7QMfkecH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "batch_size = 128  # orig paper trained all networks with batch_size=128\n",
        "epochs = 50\n",
        "data_augmentation = True\n",
        "num_classes = 10\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Model parameter\n",
        "# ----------------------------------------------------------------------------\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
        "# ----------------------------------------------------------------------------\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
        "# ---------------------------------------------------------------------------\n",
        "n = 3\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML3TGv26koOj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "79e5711e-e9fd-4db3-ff04-cafc5f119778"
      },
      "source": [
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2yEFDNrkqAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIZb3pTJk0eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhycwmy7k7fy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knOV1vJ1k9aF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O-M5q-UlGD5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6583daed-ca77-48d9-f3db-ea20fa17e0ed"
      },
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)\n",
        "\n",
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 32, 32, 16)   448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 16)   64          conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 16)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 16)   2320        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 16)   64          conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 16)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 16)   2320        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 16)   64          conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 32, 32, 16)   0           activation_20[0][0]              \n",
            "                                                                 batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 16)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 16)   2320        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 32, 32, 16)   64          conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 32, 32, 16)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 16)   2320        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 32, 32, 16)   64          conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 32, 32, 16)   0           activation_22[0][0]              \n",
            "                                                                 batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 32, 32, 16)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 16)   2320        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 32, 32, 16)   64          conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 32, 32, 16)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 32, 32, 16)   2320        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 32, 32, 16)   64          conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 32, 32, 16)   0           activation_24[0][0]              \n",
            "                                                                 batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 32, 32, 16)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 16, 16, 32)   4640        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 32)   128         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 32)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 16, 16, 32)   9248        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 16, 16, 32)   544         activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 32)   128         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 16, 16, 32)   0           conv2d_31[0][0]                  \n",
            "                                                                 batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 32)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 16, 16, 32)   9248        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 16, 16, 32)   128         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 16, 16, 32)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 16, 16, 32)   9248        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 16, 16, 32)   128         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 16, 16, 32)   0           activation_28[0][0]              \n",
            "                                                                 batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 16, 16, 32)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 32)   9248        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 16, 16, 32)   128         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 16, 16, 32)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 16, 16, 32)   9248        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 16, 16, 32)   128         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 16, 16, 32)   0           activation_30[0][0]              \n",
            "                                                                 batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 16, 16, 32)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 64)     18496       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 64)     256         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 64)     0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 64)     36928       activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 64)     2112        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 64)     256         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 8, 8, 64)     0           conv2d_38[0][0]                  \n",
            "                                                                 batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 64)     0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 64)     36928       activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 64)     256         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 64)     0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 64)     36928       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 64)     256         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 8, 8, 64)     0           activation_34[0][0]              \n",
            "                                                                 batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 64)     0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 8, 8, 64)     36928       activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 64)     256         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 64)     0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 8, 8, 64)     36928       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 64)     256         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 8, 8, 64)     0           activation_36[0][0]              \n",
            "                                                                 batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 64)     0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 1, 1, 64)     0           activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 64)           0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           650         flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib08JORDlstf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "079926e3-17f8-4a21-e961-65b16900e721"
      },
      "source": [
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, workers=4,\n",
        "                        callbacks=callbacks)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 36s 91ms/step - loss: 0.3606 - acc: 0.9117 - val_loss: 0.3556 - val_acc: 0.9021\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.90206, saving model to /content/saved_models/cifar10_ResNet20v1_model.001.h5\n",
            "Epoch 2/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.2692 - acc: 0.9296 - val_loss: 0.3221 - val_acc: 0.9132\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.90206 to 0.91325, saving model to /content/saved_models/cifar10_ResNet20v1_model.002.h5\n",
            "Epoch 3/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 29s 74ms/step - loss: 0.2259 - acc: 0.9406 - val_loss: 0.2434 - val_acc: 0.9326\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.91325 to 0.93263, saving model to /content/saved_models/cifar10_ResNet20v1_model.003.h5\n",
            "Epoch 4/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 29s 74ms/step - loss: 0.1982 - acc: 0.9477 - val_loss: 0.3375 - val_acc: 0.9042\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.93263\n",
            "Epoch 5/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 29s 74ms/step - loss: 0.1802 - acc: 0.9525 - val_loss: 0.1902 - val_acc: 0.9473\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.93263 to 0.94727, saving model to /content/saved_models/cifar10_ResNet20v1_model.005.h5\n",
            "Epoch 6/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 29s 75ms/step - loss: 0.1682 - acc: 0.9554 - val_loss: 0.1823 - val_acc: 0.9505\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.94727 to 0.95048, saving model to /content/saved_models/cifar10_ResNet20v1_model.006.h5\n",
            "Epoch 7/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 29s 73ms/step - loss: 0.1584 - acc: 0.9580 - val_loss: 0.1893 - val_acc: 0.9458\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.95048\n",
            "Epoch 8/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 29s 74ms/step - loss: 0.1507 - acc: 0.9601 - val_loss: 0.1803 - val_acc: 0.9491\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.95048\n",
            "Epoch 9/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 73ms/step - loss: 0.1441 - acc: 0.9620 - val_loss: 0.1775 - val_acc: 0.9498\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.95048\n",
            "Epoch 10/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 29s 73ms/step - loss: 0.1378 - acc: 0.9638 - val_loss: 0.1607 - val_acc: 0.9542\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.95048 to 0.95420, saving model to /content/saved_models/cifar10_ResNet20v1_model.010.h5\n",
            "Epoch 11/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 29s 74ms/step - loss: 0.1339 - acc: 0.9649 - val_loss: 0.1607 - val_acc: 0.9552\n",
            "\n",
            "Epoch 00011: val_acc improved from 0.95420 to 0.95522, saving model to /content/saved_models/cifar10_ResNet20v1_model.011.h5\n",
            "Epoch 12/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.1288 - acc: 0.9668 - val_loss: 0.1865 - val_acc: 0.9489\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.95522\n",
            "Epoch 13/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 29s 74ms/step - loss: 0.1268 - acc: 0.9670 - val_loss: 0.1556 - val_acc: 0.9558\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.95522 to 0.95582, saving model to /content/saved_models/cifar10_ResNet20v1_model.013.h5\n",
            "Epoch 14/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 30s 78ms/step - loss: 0.1237 - acc: 0.9683 - val_loss: 0.1464 - val_acc: 0.9587\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.95582 to 0.95868, saving model to /content/saved_models/cifar10_ResNet20v1_model.014.h5\n",
            "Epoch 15/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 73ms/step - loss: 0.1205 - acc: 0.9692 - val_loss: 0.1285 - val_acc: 0.9662\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.95868 to 0.96618, saving model to /content/saved_models/cifar10_ResNet20v1_model.015.h5\n",
            "Epoch 16/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 29s 73ms/step - loss: 0.1199 - acc: 0.9692 - val_loss: 0.1573 - val_acc: 0.9553\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.96618\n",
            "Epoch 17/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 29s 74ms/step - loss: 0.1166 - acc: 0.9704 - val_loss: 0.1447 - val_acc: 0.9605\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.96618\n",
            "Epoch 18/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 73ms/step - loss: 0.1158 - acc: 0.9706 - val_loss: 0.1340 - val_acc: 0.9638\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.96618\n",
            "Epoch 19/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 73ms/step - loss: 0.1133 - acc: 0.9715 - val_loss: 0.1406 - val_acc: 0.9624\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.96618\n",
            "Epoch 20/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 73ms/step - loss: 0.1118 - acc: 0.9722 - val_loss: 0.1971 - val_acc: 0.9429\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.96618\n",
            "Epoch 21/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 73ms/step - loss: 0.1109 - acc: 0.9722 - val_loss: 0.1465 - val_acc: 0.9604\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.96618\n",
            "Epoch 22/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 29s 73ms/step - loss: 0.1103 - acc: 0.9725 - val_loss: 0.1354 - val_acc: 0.9628\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.96618\n",
            "Epoch 23/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.1081 - acc: 0.9729 - val_loss: 0.1300 - val_acc: 0.9648\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.96618\n",
            "Epoch 24/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.1074 - acc: 0.9733 - val_loss: 0.1537 - val_acc: 0.9574\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.96618\n",
            "Epoch 25/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.1064 - acc: 0.9738 - val_loss: 0.1235 - val_acc: 0.9680\n",
            "\n",
            "Epoch 00025: val_acc improved from 0.96618 to 0.96802, saving model to /content/saved_models/cifar10_ResNet20v1_model.025.h5\n",
            "Epoch 26/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.1057 - acc: 0.9742 - val_loss: 0.1383 - val_acc: 0.9629\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.96802\n",
            "Epoch 27/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.1045 - acc: 0.9744 - val_loss: 0.1473 - val_acc: 0.9599\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.96802\n",
            "Epoch 28/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 73ms/step - loss: 0.1043 - acc: 0.9744 - val_loss: 0.1882 - val_acc: 0.9500\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.96802\n",
            "Epoch 29/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.1028 - acc: 0.9752 - val_loss: 0.1404 - val_acc: 0.9631\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.96802\n",
            "Epoch 30/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.1031 - acc: 0.9751 - val_loss: 0.1334 - val_acc: 0.9641\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.96802\n",
            "Epoch 31/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.1017 - acc: 0.9755 - val_loss: 0.1439 - val_acc: 0.9609\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.96802\n",
            "Epoch 32/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.1004 - acc: 0.9761 - val_loss: 0.1936 - val_acc: 0.9446\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.96802\n",
            "Epoch 33/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 73ms/step - loss: 0.1011 - acc: 0.9758 - val_loss: 0.1680 - val_acc: 0.9546\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.96802\n",
            "Epoch 34/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.0995 - acc: 0.9763 - val_loss: 0.1305 - val_acc: 0.9663\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.96802\n",
            "Epoch 35/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.0995 - acc: 0.9761 - val_loss: 0.1180 - val_acc: 0.9694\n",
            "\n",
            "Epoch 00035: val_acc improved from 0.96802 to 0.96937, saving model to /content/saved_models/cifar10_ResNet20v1_model.035.h5\n",
            "Epoch 36/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.0989 - acc: 0.9763 - val_loss: 0.1483 - val_acc: 0.9608\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.96937\n",
            "Epoch 37/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.0985 - acc: 0.9765 - val_loss: 0.1399 - val_acc: 0.9629\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.96937\n",
            "Epoch 38/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.0995 - acc: 0.9762 - val_loss: 0.1494 - val_acc: 0.9599\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.96937\n",
            "Epoch 39/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.0975 - acc: 0.9769 - val_loss: 0.1238 - val_acc: 0.9693\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.96937\n",
            "Epoch 40/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.0977 - acc: 0.9768 - val_loss: 0.1238 - val_acc: 0.9674\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.96937\n",
            "Epoch 41/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.0968 - acc: 0.9775 - val_loss: 0.1575 - val_acc: 0.9582\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.96937\n",
            "Epoch 42/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.0972 - acc: 0.9772 - val_loss: 0.1276 - val_acc: 0.9669\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.96937\n",
            "Epoch 43/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.0963 - acc: 0.9775 - val_loss: 0.1707 - val_acc: 0.9550\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.96937\n",
            "Epoch 44/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.0953 - acc: 0.9777 - val_loss: 0.1577 - val_acc: 0.9580\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.96937\n",
            "Epoch 45/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.0955 - acc: 0.9777 - val_loss: 0.1394 - val_acc: 0.9621\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.96937\n",
            "Epoch 46/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.0961 - acc: 0.9774 - val_loss: 0.1517 - val_acc: 0.9604\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.96937\n",
            "Epoch 47/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.0955 - acc: 0.9776 - val_loss: 0.1548 - val_acc: 0.9584\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.96937\n",
            "Epoch 48/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.0956 - acc: 0.9776 - val_loss: 0.1323 - val_acc: 0.9653\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.96937\n",
            "Epoch 49/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 72ms/step - loss: 0.0948 - acc: 0.9780 - val_loss: 0.1345 - val_acc: 0.9632\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.96937\n",
            "Epoch 50/50\n",
            "Learning rate:  0.001\n",
            "391/391 [==============================] - 28s 71ms/step - loss: 0.0946 - acc: 0.9780 - val_loss: 0.1445 - val_acc: 0.9620\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.96937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_C_ZBI-l2Pn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ee2deb67-4319-412e-f865-7fd03a262fba"
      },
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 159us/step\n",
            "Test loss: 0.14451811759471894\n",
            "Test accuracy: 0.9619599988937378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F8ugwp7wn1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GRADCAM\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj6GCh62w2_z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "08fca8ff-a11b-4fc9-cc6c-c94b5dbbfdbb"
      },
      "source": [
        "#model = VGG16(weights=\"imagenet\")\n",
        "#dog\n",
        "from skimage import io\n",
        "dog = io.imread(\"https://www.rspcapetinsurance.org.au/rspca/media/images/hero/dog-insurance-hero.jpg\")\n",
        "dog = cv2.resize(dog, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "x = image.img_to_array(dog)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "class_idx = np.argmax(preds[0])\n",
        "print(class_idx)\n",
        "class_output = model.output[:, class_idx]\n",
        "last_conv_layer = model.get_layer(\"conv2d_41\") #conv2d_42\n",
        "\n",
        "grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
        "print(grads.shape)\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "print(pooled_grads.shape)\n",
        "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "print(conv_layer_output_value.shape)\n",
        "print(heatmap.shape)\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "heatmap = cv2.resize(heatmap, (dog.shape[1], dog.shape[0]))\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "superimposed_img = cv2.addWeighted(dog, 0.5, heatmap, 0.5, 0)\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow( dog)\n",
        "cv2_imshow(superimposed_img)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "(?, 8, 8, 64)\n",
            "(64,)\n",
            "(8, 8, 64)\n",
            "(8, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAHh0lEQVR4nLWVeYxVVx3Hz/7u8u59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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F324E923978>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAGoElEQVR4nLWWy48cVxXGzzn3UdXV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\nPbNorQIzADKLIlJKIWJg8ALeP+zW/Cd0t4G9j3H03gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F324E923940>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EwPrClC1rOC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "3cc09a61-c99b-481e-95e7-017bdf4edd29"
      },
      "source": [
        "#from skimage import io\n",
        "horse = io.imread(\"https://cdn.britannica.com/96/1296-050-4A65097D/gelding-bay-coat.jpg\")\n",
        "horse = cv2.resize(horse, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "x = image.img_to_array(horse)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "class_idx = np.argmax(preds[0])\n",
        "print(class_idx)\n",
        "class_output = model.output[:, class_idx]\n",
        "last_conv_layer = model.get_layer(\"conv2d_41\") #conv2d_42\n",
        "\n",
        "grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
        "print(grads.shape)\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "print(pooled_grads.shape)\n",
        "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "print(conv_layer_output_value.shape)\n",
        "print(heatmap.shape)\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "heatmap = cv2.resize(heatmap, (horse.shape[1], horse.shape[0]))\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "superimposed_img = cv2.addWeighted(horse, 0.5, heatmap, 0.5, 0)\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow( horse)\n",
        "cv2_imshow(superimposed_img)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "(?, 8, 8, 64)\n",
            "(64,)\n",
            "(8, 8, 64)\n",
            "(8, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAF2klEQVR4nLVWzW8kRxV/VV093T09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\n6lEVLAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F324E7ACBE0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAFf0lEQVR4nLVWS4wcVxW999arb1d/\npj1uJ3hi8g8RCKTAhj1CygYhgoSEglCAGMWgyYzjccYYRZGMg7Am48lgISdLFvwWCCJQYBE+KwQs\nI1kySqw4sT2xxzPT7q6urnqfe1mUpzUeT3oiYc6u6p13zrvvnlf18MUX/wb/BzAzIgKAuuPS//j7\nv/791lu2LGcPP3PHDITl5cVXWu3Jybsfnerc1e2+KdZUQ/+rATMvL58t9NADGQ756pX3rfOm7v1s\n7/rbd8Dg9NIZ8lSpC6NN3Gh4Hg3611QjJlVrtDsO0APZxUBERKRq1+jNiRMvIVK90UAkaxgRnXPD\nPGemKEx9FxaD6+QFf339z1/40hdvMXj7P+/+9vXfKQqAFIEwIADpojc/f5hFROTUwnItabQm9gWh\nr03hrDG6BCIiD4CEZWPjyscf+/z5f77X2rP/8urGLVu0tPSaiAuiVHmp5ylmGyf1fNBXKvzpmZ9b\nqxFgsnMf2sFkZ//Fd84NjQFg8hSzS2opAwHhE0985Y3f/xF0EX3ic+aKQQCq1BcXlv0g6ux/tD3x\nIDAQWauzIu/7YU0FkbEWVRDF6TC7UWi++O75MK5HcaTznnWWnWT9bkA4M/P0Iw8/MDM3LXH62GcO\nmDAClJsGtdZUlLY98lmK5r57rNFeELc/9mBZDK0zSdpMkwkG8lQIQABB0piMw3Yt7aBQszkx0Zy0\nptxUk2dnn/nTr3+VJvHS6TMEAItLZ+rNPQGpXncly29sXD6ny2Fz8oHu1feUUqHf0qVxICzomAG4\n1blfKKh1pmqtThzXjTEMdGRuRkSq5ZLI9PS39XCtKI0SERApBt0suxFEjSCgXuaUp/IsYyIS8Mgo\n3w8VIfhEEZAHYstyAFkvUpSLEMLszMGtYUFCEPjG1x4HeFwBgHVuWAx9paJAWQTfj5zVvbULYRjX\n2/eU+boiLHUpIsUw88PYap002srDOKlleVbk3Sq+W9M8ggIAYfYIrSMvaubrFwUYhMJQEYmTgsgj\nq41YRAz8kMhndgRcDsvsxmqz2fj+oSfHGBAAKKXy0igPy8GqtqA8IgVemDprrq+8P8xWSy4dl0GU\nluWgKLpBEButETHPumtr18ao36xgWBTtJMnz9SAIwAytR84WoREkL1TgGERrIF5fveSHEVvurb8T\nJHvyQS8KI+dkFwMRQQDCDEF0kQMRefHh6aehigTi6cWzLBQFCeuBMxqQ6hMH+muXJzr3uWJDrB2j\nfrMCx+7a6qV6ehezbXXuH2TXYTNwIDI7+91bEoK4sLCUpPv6vQ+KrP/83PfGGxAipnHcat3th2kQ\nJXnvquTZh7Gr3Tj83LPkReDc0blDleVW++0GAPCdgwdBPHTc663ooj89860xBtWissEaG42wXW50\n1kZQiPjqq6/5fuqkBMAg8MfUW2Hx5WUA4u1SgIg7GAAAMzPrfNALo8jZcrw6ABS6JPKUv/1fcrs6\nVCkSZm0KpZS1dgfKTiCf2LmPwlQAwCJstDiLpJh5d3Uiqy18BCZUTSYiFpi69yEA9qNo1zllqUmp\n+fm5XZkiQgDAIsDQ764dP36MrR0/Z+WDa3EcKxUQ7ZKFqiWEiER0dP5IvTa5dRgRq1RUPNzEH954\n8+jcTJokW1uKO6EaonPnL7BzgaJvPvVVAHDWnnzpFGy5T1RU2US/uyYiaaO97apxOyoC/eaXvzDG\nwOYhPHbsiO/7YwofFkMAWLl0Yfz+jCoj5VEQBKPlIGCYNE+e/MmHravd7pz40Y+xyE8tLO5I2AY6\n/sNj+6cObJWbPvRUkqavLP/s9pYAgDYFO579wfOf/uSn7K2J2LET+MILfzm7uFSo9Mmvf3nv3r3b\narz9Wjd6dM4R0bbvyigRozf/BZUAPRJBm7WCAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F324E7ACBE0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arAHXWyi3SED",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "bae47e43-76dd-4e52-b595-2296bf06d97b"
      },
      "source": [
        "#from skimage import io\n",
        "cat = io.imread(\"http://imgstocks.com/wp-content/uploads/2014/01/File-cat-march-2010-1-jpg-wikimedia-commons-1280x800.jpg\")\n",
        "cat = cv2.resize(cat, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "x = image.img_to_array(cat)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "class_idx = np.argmax(preds[0])\n",
        "print(class_idx)\n",
        "class_output = model.output[:, class_idx]\n",
        "last_conv_layer = model.get_layer(\"conv2d_41\") #conv2d_42\n",
        "\n",
        "grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
        "print(grads.shape)\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "print(pooled_grads.shape)\n",
        "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "print(conv_layer_output_value.shape)\n",
        "print(heatmap.shape)\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "heatmap = cv2.resize(heatmap, (cat.shape[1], cat.shape[0]))\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "superimposed_img = cv2.addWeighted(cat, 0.5, heatmap, 0.5, 0)\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow( cat)\n",
        "cv2_imshow(superimposed_img)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "(?, 8, 8, 64)\n",
            "(64,)\n",
            "(8, 8, 64)\n",
            "(8, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAF+ElEQVR4nLWUe0xTZxjGTw+nhd4O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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F324E5CBEB8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAFSUlEQVR4nLXU22/bVBwH8OPb8TWJ\n7TjOdUl6WeiqFtYJBgwm9jSJFwQ8IIHE/7L/AYnXPcDDBBOXSRMSSFMF3RRVW7e1W9ZkadYlWZrm\n4jiJ49iOfcwLCKSlXVep5/X49/3oe46OsStXVsFJLvxE018P+PWPtRME1vL3xIBwa714UkCjM/I9\nhwSTkwI8D8UioutaB32AEKpXyscHgoGAYVgCAze3d1/erTyvreY3q/oU/qhAr6sbpuO4qNHqeI79\n/y2EUEP3aJpqtVovD5JHSUcABOVQoVhOp9Nat/nNt2tZVex2el989XW3p1W6bjoudtr903O5YwK4\nDx5tlWIKI/CMNeZgPAFZiBnOvcePIRcSA0F34nIse2YuMWX2KADwXBxZEVXSdY0gKUVVDcftGYZl\nTzgp3B9aAAM9E+D4lLQjNdjY2AiKFAX5avmBh+OWaSzkcolEkuGEzQcPU6nsRqGG+wCAKUd0pAaP\nSiVVCdd3i/FsNhWPWZZljIygKGu6jlwXMqS2t7+8EJ86eySA5wVRYB3Xq5bL4bC8tHzWsZ2RZder\n1bMrK4osLS1lR5YzdfYIR+S5tVrVdlNBMbxw7i0EMNZCDMv0OprWalSePqFoPhxPnl+aOWaDP1dX\nOY7brTzDKbpvDv+6s97qdIzBsN3pJGYXCeAzLNOu1wDyjwmUn1cb9fr83GxM4k3bmlmcz6SSAs8v\nn3tbUWP9wTCsKKdz2YGuHQfwAZq4bjr3phAMFUvliBgr3LltTnxI83PZtBIXLl26cOPa92Z/yAuB\n4zXAPIRn0imO5wBO3Pr9t8XzHws8o6Yyv1y/3nzRzN+5e/nzL0ulIkESU+dfccl7z3aisUQ+fzee\nTIwM68LFj57uVOp1Uo4Yg34HfxGAYKJalt7r+r6PvXYD312/vwkhHmZwmhdzC2/0zTEBBd8cjHr6\nyqXPgjzNyfGIJCixNEZQUzMOA65dvUoz9MgYQSXJAGchG5fkqGF5tDKLOQaB+e+892GrttNsa4tL\nSweF/AP4PjKHenl7K383j1wHIHTj+jXbnRAkZVpOOMiMHK/Z3BtYiKJIs/lETkT3m60nha3Ln3z6\nrNZstTsHASQAYKRrGxv3n+7uOs6Eg+SD2/kgCyFNj+0JwzCqGjHHToBCETXidIyLK1ngp6EgVwfe\nKYkzLTOXO72UkQ9s4Frm/YePHha2PeRzDAMAHkvETYx0CUpWoxPk5+bSjb3GB++/u7FVUgRc1zrb\nxR0IbJF0WcKtNXUwGcty+ECg8Liw1+4NBsNQQGA5joRUR++7HsJxgmG5kBAIBoKyEv3uh5+ViPq8\naYQkaXFxgeO4U6pQqbWM4WA2FT3kIvFWV282GwLPYQCwDBSEAKQZjhdICF/sNR3P+/GnmwSwcZwq\nl3dxkqrs6SwLtaHVHbpcgJvPxpIJ9TBgbDn9gW6OTc9DOIZjABiGIfAczbCSJK6vr4uqSuBkKjun\ndeqm4wwtdHOt8HxfHwwNhsAzahADUx/Av4A2MFQlHBCEoCg2W+2ursuiWCqWfIQyqTQAxEw2s71d\npGmYyS1LIYllGOQDlqHtiWtNPEkQDkkHAOA0hKZphkRR63Zt21Zk2XLd3JkzQSncbu+HI4rj2Kn5\nRX2/DhkWYaQxtiNRxfX8AM8wEKNo+ArAGo8ghD4AFEWF1ahuGCQJkY8Z5hgR9Kl0yhmbqUQUINu1\nTOSMJTEwMc3dRksfGK2WBqb/pP9bpI9RHkKQJEeWA0nPmUyA7yMMS6SS5misa4OWPkrPpHXTT4q4\nPuy7HlLCsmlaAY6VoiKGHXYBAIC/AY3KnR/kTJLBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F324E7A2780>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k55Z0tBt6OAH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "eaf61478-dc5b-4e2b-bea4-7a0f7ad78cc0"
      },
      "source": [
        "airplane = io.imread(\"https://compote.slate.com/images/222e0b84-f164-4fb1-90e7-d20bc27acd8c.jpg\")\n",
        "airplane = cv2.resize(airplane, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "x = image.img_to_array(airplane)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "class_idx = np.argmax(preds[0])\n",
        "print(class_idx)\n",
        "class_output = model.output[:, class_idx]\n",
        "last_conv_layer = model.get_layer(\"conv2d_41\") #conv2d_42\n",
        "\n",
        "grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
        "print(grads.shape)\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "print(pooled_grads.shape)\n",
        "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "print(conv_layer_output_value.shape)\n",
        "print(heatmap.shape)\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "heatmap = cv2.resize(heatmap, (airplane.shape[1], airplane.shape[0]))\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "superimposed_img = cv2.addWeighted(airplane, 0.5, heatmap, 0.5, 0)\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow( airplane)\n",
        "cv2_imshow(superimposed_img)\n",
        "\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "(?, 8, 8, 64)\n",
            "(64,)\n",
            "(8, 8, 64)\n",
            "(8, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAIuElEQVR4nE1SW6ylZXl+j9/3/f86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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F324E5CBEB8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAHUUlEQVR4nD2WS49dVxGFV62qve+5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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F324E5C4DD8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33ws5bLG6rAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "710628f3-48ee-4223-9e3c-c4814b11633b"
      },
      "source": [
        "automobile = io.imread(\"https://img.theweek.in/content/dam/week/news/biz-tech/images/2019/9/1/Automobile-slowdown-Sreemanikandan.jpg\")\n",
        "automobile = cv2.resize(automobile, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "x = image.img_to_array(automobile)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "class_idx = np.argmax(preds[0])\n",
        "print(class_idx)\n",
        "class_output = model.output[:, class_idx]\n",
        "last_conv_layer = model.get_layer(\"conv2d_41\") #conv2d_42\n",
        "\n",
        "grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
        "print(grads.shape)\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "print(pooled_grads.shape)\n",
        "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "print(conv_layer_output_value.shape)\n",
        "print(heatmap.shape)\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "heatmap = cv2.resize(heatmap, (automobile.shape[1], automobile.shape[0]))\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "superimposed_img = cv2.addWeighted(automobile, 0.5, heatmap, 0.5, 0)\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow( automobile)\n",
        "cv2_imshow(superimposed_img)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "(?, 8, 8, 64)\n",
            "(64,)\n",
            "(8, 8, 64)\n",
            "(8, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAHxklEQVR4nLWWeWxUxx3HZ+Yd+/Z6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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F324E512860>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAHLElEQVR4nLWWa2xUxxXHz8yd+9z1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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F324E512860>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7VEDQ1y7S1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "61be4a1e-9b10-4507-b3ca-ac53201f054e"
      },
      "source": [
        "bird = io.imread(\"https://www.hakaimagazine.com/wp-content/uploads/header-gulf-birds.jpg\")\n",
        "bird = cv2.resize(bird, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "x = image.img_to_array(bird)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "class_idx = np.argmax(preds[0])\n",
        "print(class_idx)\n",
        "class_output = model.output[:, class_idx]\n",
        "last_conv_layer = model.get_layer(\"conv2d_41\") #conv2d_42\n",
        "\n",
        "grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
        "print(grads.shape)\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "print(pooled_grads.shape)\n",
        "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "print(conv_layer_output_value.shape)\n",
        "print(heatmap.shape)\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "heatmap = cv2.resize(heatmap, (bird.shape[1], bird.shape[0]))\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "superimposed_img = cv2.addWeighted(bird, 0.5, heatmap, 0.5, 0)\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow( bird)\n",
        "cv2_imshow(superimposed_img)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "(?, 8, 8, 64)\n",
            "(64,)\n",
            "(8, 8, 64)\n",
            "(8, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAI1UlEQVR4nC2W/a/X5XnH3+/ruu/P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\nrUDV1G8aRgzNjOoUr0YyzP4PRgqlketxLsAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F324DB7AF28>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAHYElEQVR4nDWW3W9dZ5nF11r79cnx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\nRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F324DBC3E80>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVDZCSxW70tl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "b0d6f8a0-c099-4959-d998-e10b19dc24fd"
      },
      "source": [
        "\n",
        "\n",
        "frog = io.imread(\"https://ichef.bbci.co.uk/news/320/cpsprodpb/103CF/production/_106211566_scheele2hr.jpg\")\n",
        "frog = cv2.resize(frog, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "x = image.img_to_array(frog)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "class_idx = np.argmax(preds[0])\n",
        "print(class_idx)\n",
        "class_output = model.output[:, class_idx]\n",
        "last_conv_layer = model.get_layer(\"conv2d_41\") #conv2d_42\n",
        "\n",
        "grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
        "print(grads.shape)\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "print(pooled_grads.shape)\n",
        "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "print(conv_layer_output_value.shape)\n",
        "print(heatmap.shape)\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "heatmap = cv2.resize(heatmap, (frog.shape[1], frog.shape[0]))\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "superimposed_img = cv2.addWeighted(frog, 0.5, heatmap, 0.5, 0)\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow( frog)\n",
        "cv2_imshow(superimposed_img)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "(?, 8, 8, 64)\n",
            "(64,)\n",
            "(8, 8, 64)\n",
            "(8, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAJ/klEQVR4nI1PWYxdZQH+1/Of5Z67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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F324DBB2C88>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAItUlEQVR4nJ2Qy49cVxHG69Spc+7t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\nTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F324DBB2A90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViDN75MM8Mvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "af742048-abbb-4c45-b874-02c5cf324d90"
      },
      "source": [
        "\n",
        "\n",
        "ship = io.imread(\"https://specials-images.forbesimg.com/imageserve/5dd2ed8de0af7b0006b19dfc/960x0.jpg\")\n",
        "ship = cv2.resize(ship, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "x = image.img_to_array(ship)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "class_idx = np.argmax(preds[0])\n",
        "print(class_idx)\n",
        "class_output = model.output[:, class_idx]\n",
        "last_conv_layer = model.get_layer(\"conv2d_41\") #conv2d_42\n",
        "\n",
        "grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
        "print(grads.shape)\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "print(pooled_grads.shape)\n",
        "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "print(conv_layer_output_value.shape)\n",
        "print(heatmap.shape)\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "heatmap = cv2.resize(heatmap, (ship.shape[1], ship.shape[0]))\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "superimposed_img = cv2.addWeighted(ship, 0.5, heatmap, 0.5, 0)\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow( ship)\n",
        "cv2_imshow(superimposed_img)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "(?, 8, 8, 64)\n",
            "(64,)\n",
            "(8, 8, 64)\n",
            "(8, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAKcklEQVR4nAXBeaxlZ0EA8G89+z13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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F324E965828>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAI9ElEQVR4nCXU3Y4kSXUA4BMnTkT+\nVFZVd3VNd88Py2iYZccLC6M1uxdI2AJZwAWSJcviyhISD+BLP4UfggfgxgYsywYLmWWEbBgt4wUv\nPaPZGeid6Z/q6qqszMiIyBMnfOHvIT71D9/7x4RKZaVJJZaMoCVnBZzFUAGgJLFSkEVQodKgETkr\nVAoAMnBwUXJCbbTWoe8BpCxKHiOmxDwaheQ5EGplSITIFgCAkFmSTgySJSdQoBBjDMaQBpMEQBJn\n0BqyCECWkSFJFEZQRLZvW61Rg0LEYfCE2nDOGEXA4Uhk0PtY2jpGMTYDoWJQqKuyQdIsHEcutXZd\nV9aFsIgksgZJQ1QI4L3jkU3RjN5xiKSJZIyoceRRE2kNwfsMENkhaZYAEbLkFFNRFMCZyHBwTmsi\n1e52zaQpyjpn1Cqj1dF7BVhWFUgqyzKRCW6glFgyZBFrqpREE0FiUOAGZ61Bjag1gCKtJQNLqusZ\nADDHGrUC3TuScgW7VNupMUQaQYRDzKgyj9ODGhVC5LGs6ziyKauyKskUqLEsSmOsIYuamlmTRCSL\nJfK+UygpS93MMsT/eny83ZTWvl+XB2PyksQ552IY2m56PCsnM8oyNnUd/SAAwiSIpCmTRcosMQNo\nrceRMyKhJprWe2VhbUYHoK7aia6f/ebxunX/8eB+dbw3KfP1/v5+8q45Xo4SZHuG1XQmGYwtSlug\ngsQCxnAIoMGWDVKtNCmlQDiDPP79Zc7dMHSFhufne789SV/40l1r5KtfObo7z5vVn5qmGdpWJjXa\nCXfsBqJutwORqm6SCCRB1CjRlgQskiNpHEPUGiFDzvnZ+Y279+48++TDuoiA7cO3zatnH737+fqP\nr5+vRBbTmlDM3Xeq5VH3/MOLs3VtCd1ma5q6qMr9xT4RGVQAUNuSUyRCrSkOvWQmog8e3z2+Lb98\n9OTG/vLw8Pitz91/+vRlhe756zMiq5G6frf35sP5Yu7/8POLT16EGJNoOjy+EX3sfQyGirpRIKhg\n266zoEgqjZns7z9+cvqFB/e+8Zd0udqcymZ/cby5OHMXz8NudSUzlXPksNmMGcjHRJuT00/bmEHG\ntPM9atSZU2GtyhCjB5H16rIiiwggY7e97NYXX/7K+90uvnr1QuPss/ce/OaDf5OwOXn5Cm2JCgzZ\nw9mddfe5g5m17B796ncuRPa+mU4LQOydK+rCD0PvnNE47LrFwcF6fZXH+PpPpy8u4NdP1588Pzl6\n6+2Tj//n0X/+LIaNQnrx6aktbFPXzrvoh076tz/zmqrm9OnJ8uCgKKiZzXZtq61V3//23y+XSx9j\nOal939V1Ayhtu7Nk0drVZnCc7735EDJYY1DBv/7knyUJEYoIokalBGlisChnZRmtQIwxCY8szEyI\nVNfTXdcVZbm5WvsYAfXF2blkmc1nC2uiW7/1/t/+4qc/Plwenn36SchKwqiN5qwoN103PboZUnCB\nY4nD+dm2MtC5wSpV1XVV/P9ykQEyM8cY500jI9+6c2tvvtdudpzk/sNv/OLffzSr7f3PP3j43tdS\njEUz8VHWq/yqXx8ebFNwGbGZmfOLc6URyNZVhbbc7Lq+G6wt8Xpz3bb96R9fXK/XLrAfx13boqXS\nmovL1dW1e/jn70FGTgICauTN1ebGYiFK7h/OQaEQHh3VfbcjKkaO66uroq6jyGI+XwX/ervD6bQK\nDC6Ctfb66nK93rw+u0SBgfnuw7+6cXyr63a7vpcsZ69PgfDBm/f+7J0vTksHAAAwbeDV69Xgs49B\nRLCoBh+aqlq3u4kt90qDq22vMO0tFufrraC2hIfL5cVqrSJjOeEEN49uTsuSWT76+OSztw837fr3\nHz4+WN6Iko5vL9rNABldP5RlZYwlBZKyH8OIuvXBhREt5K4bQHg+ayiDZLXb7dp+8AogKea4c/70\n4vIPT/77zuH81082kSECeM63bt0hrRUoHmNZ1cH1zvmyrvvB+cilNZOycG7AbRc0gHMMWWdNiBq1\nvbnct2byLz/64frVsxdPP5rPmhBC2/fLBeyce+Otd5cH5vju3a7rAG3VLFzwimiMvOk6S7bvXPQ+\nhjjEhGiJ7KSqaxf84MLLy3ZkuN52b3zxvejji5enF+dnzvl+cJvOO8jvfPVbr14+utik0xcn5WzR\nuW69OiOlEjMVFpJo0jEGRBoiK1AkzEPqQZUiYGszYW5dP20mZye/a6bN2fm5SEYiyfIXX//mrduL\n/33yuGlmb3/p4aOf/0xSFFE8JluWMYTJhGIMLkZFtotBK5jNG/X1L//dfFpvWmetyTm7IbLkSTPh\n6BzMovdoq29/56831+uPf/tB8FvnokKFSByZoyiltMaY06w0qIvIXFmbJIUwikjOieazmR9iXdfO\nB1vaHFlDgix7zV7s0jf/5ruo8af/9IMEOYuKUUSUgArRGxRDloi6XU9ad2kEGCEz4exyvZ00BUdu\nJg1db1tFelHvBQbnhsLQLo61RhfHd7/2rV89+iW7No44hpGsCT4qjSmJ0YiKQhy1pqIoyJJ3XhRC\nxsEPn7lzvN5s66poXafef/Dd2WwvJYkxFmXp/ZBSSiKSxBibJI88JhbJ4MckIlVdjJ4VYlUayKnt\nfV1YVGiLwg89IIKA1mo+n65WLWqFk2aPWVJiTiACY8qSFQCKwt5570MMiQXCKIbAFsWudQKgSfkw\nSsa6rhXiyBzHEVF3Q0RDY1anZ2tQglpTBgwcdl2wBneXlwrVfLY3uB5AAWBMSTIgQM4yMqbkibSI\neJ/Ksui9V1n2ZrOqLEEBc5ohpcSTsuIYbFUPrqeL9TWKgFKkS8S4WCzPzs4Wi+X1eqWsFcmoMMTR\nGMo5IyIZSsIgWiRrQoPFetsCQGGLUWBSmV07hDBaY6MfIwvWtiDSqFAg+8hX6/VyuYgcxyTMSUQi\ns7UWMmTJMY4aCUAZgwJZGNzg67qeTRrnB8TsQ2wm9fHREjE5PyASsjCg3XTd9fralnWIvGn7i6sN\naCKlOIktCLWSnEEpYwwzg6isCARsQUVhnBtc9Ldv3TSoNaLz/mqzAyzeuHNUlPr/AAv79u2bHICr\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F324E965828>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5ApbkT88nJM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "893242b7-6ad8-46eb-92cd-bbff4269d4da"
      },
      "source": [
        "\n",
        "truck = io.imread(\"https://www.team-bhp.com/forum/attachments/commercial-vehicles/1330981d1421754384-volvo-eicher-launches-pro-6000-series-truck-pro-6031.jpg\")\n",
        "truck = cv2.resize(truck, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "x = image.img_to_array(truck)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "class_idx = np.argmax(preds[0])\n",
        "print(class_idx)\n",
        "class_output = model.output[:, class_idx]\n",
        "last_conv_layer = model.get_layer(\"conv2d_41\") #conv2d_42\n",
        "\n",
        "grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
        "print(grads.shape)\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "print(pooled_grads.shape)\n",
        "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "print(conv_layer_output_value.shape)\n",
        "print(heatmap.shape)\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "heatmap = cv2.resize(heatmap, (truck.shape[1], truck.shape[0]))\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "superimposed_img = cv2.addWeighted(truck, 0.5, heatmap, 0.5, 0)\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow( truck)\n",
        "cv2_imshow(superimposed_img)\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "(?, 8, 8, 64)\n",
            "(64,)\n",
            "(8, 8, 64)\n",
            "(8, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAGaUlEQVR4nO1WbVBU1xk+537u1727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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F3241FD9EF0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAF0ElEQVR4nO2Wz28b1xHH5719+3a5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\nTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F33657C5550>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7eblAlO9srp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "4548c364-1d4f-4990-89d1-ee1d10068daa"
      },
      "source": [
        "deer = io.imread(\"http://www.yedraw.com/forest-animals/deer.jpg\")\n",
        "deer = cv2.resize(deer, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "x = image.img_to_array(deer)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "\n",
        "preds = model.predict(x)\n",
        "class_idx = np.argmax(preds[0])\n",
        "print(class_idx)\n",
        "class_output = model.output[:, class_idx]\n",
        "last_conv_layer = model.get_layer(\"conv2d_41\") #conv2d_42\n",
        "\n",
        "grads = K.gradients(class_output, last_conv_layer.output)[0]\n",
        "print(grads.shape)\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "print(pooled_grads.shape)\n",
        "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
        "\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
        "heatmap = np.mean(conv_layer_output_value, axis = -1)\n",
        "print(conv_layer_output_value.shape)\n",
        "print(heatmap.shape)\n",
        "heatmap = np.maximum(heatmap, 0)\n",
        "heatmap /= np.max(heatmap)\n",
        "heatmap = cv2.resize(heatmap, (deer.shape[1], deer.shape[0]))\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "superimposed_img = cv2.addWeighted(deer, 0.5, heatmap, 0.5, 0)\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow( deer)\n",
        "cv2_imshow(superimposed_img)\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "(?, 8, 8, 64)\n",
            "(64,)\n",
            "(8, 8, 64)\n",
            "(8, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAE4UlEQVR4nK2We0xTZxTAz+3rtlIY\nlAK2dGBpzAa6iBs+kNcGJmMiIzIn7uFQJ4lZMP5h2DSbS5YlSzRZ2NiWTaPTMIlORVQGYuZgUx7L\nQB4qI7xu6btQHm1pb1/33m9/FAsiKbdm56/vnHvO+X3n3O9892IIIfh/BQFg8xonuLNpfDLU/BQN\nAMCwBIybHADwa10dy+y9AwMnPvsWEBoiRlkBJggDADgmKJaA1ORkhqYOHzzeXt/FCqDTEJ0d2vz8\nHJYAAHh7104XSZaUFW7PKkEIAVpOOuvv+nz06JhxWU+EUEX58W++OLtlfSbDMH7LMhUAwPqCzCs/\n/1Zz7sZC48eHjy1U7/3d4V9YpvTpeevauu9h2OOTxGZfDMP8UFXT2NhWduCo36KIVy50wCPECKHS\n3eV7duxfFIsh1nNQdeqnW013+BzIXrv5u1++1xBjfvuhss/D+ZxBy2jt5WrAsEVRIQD8UvreQR5X\nqNYMYfjaSJFFrZlSpcQ6HM6cnNePHtn7tH/IAADYuqn4rdIi7xRDMSKpFHuoHmm+Xdf9sGtJ52cB\nAAAg6G3TNly7oExZ8+6BN5+4HBZ7PpP81fzn2bP3MlJfsk7NIiaYJ28Rr+V3j86sFwoFaq06RhIt\nkUj7Hw0fOZau0c02NYxKJbGNt6/mF+Rp+80qmVAsV9bWX99f+n6QUucB5V/16NT/FKRvNJinvW6P\neIXI40F8Hm9VkuL6FXP/iJrGOLhrcP++vRdqr+/OS1MmiL6utk4Q9uC9nBu0k+fbXZTd6iS7Hg3S\nHkouUxgmzIPq/hE1QdFU6/2OnqFHNjtptDt1EySicQFFGS3jJz/9Um00BAfMVdDU3NnT3rwmLWfK\n41a7jEK9nqZJZWycVBL9gCAcpBfjgIO0innY5Uun+WExDrd7jNCcqznd3dPCCtDf3ZqxdRuGuDZy\nFpBgxut2uVxmG2GyWcFHuyifCA+PiY2yzYynJCatjAaMBzqzXp6gCHZ+ACBwTNdlvgGSdI9tcnrG\nESaLj8RxHhcLi4jic3nh4UJy0s4T4TOTZpVCNu1w2I0PVsdF6e3Dt2/cDJ59voK+1luZO0+QDMX1\nzXKdOhcnjpq2zjqmOBhwcaEqPsk6M5u4+oVhLeEw6YS4UCKLKSgpWjY7LPwe+ICRK5JcE917CnPA\nNo5zuLZxjds2qW+/8MfF4yMmy/DwqJNxRvEIZaLYjVDx9mw2gPlJzth1grHcXykX1tVUv7KpyM6N\n8rpdOC7weiFFKfXxxQyIhjpqwiKfUyWlNFw7wyb7fAWVp24YiJ60lxPraqoBYHDgrr7vqiLKY/j3\nTlKkpfFqpVFvwwUCUUREuHgF++wAAAihk5VVWws/qL3Z4B/uuLjnPzz0ydPzv72komjHjliZLKRL\nhQMAycmvqgf6igu3+ZEmkwa4gD11CUZHcxJWqfr6HoSwfX+LGltaRoZ7AyYMw5wztn0HDi9ylcsT\njQbtyhhpyACtRh/YrX9x8fyPjEhIwRNF5Gan+jwMhCoIoayCsiXbl5+bv1ClGGbDxi0hvYC5dyCL\njViSHa96MT0rd75YhAn4eKgFcBiA11I3LPmsouKjhPjEgNrc2k66fCzzBpqL0Wz+jQAA4J3Scvv0\nZEP9JZaMOWEQohGiWXSTdLs3Z+QF1EDUwnDmsSUg/wGag/XCE74GvwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F3241FB2630>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAEpUlEQVR4nK2WbW8UVRTHz52Zfezu\ndPq0KbW0Sy2toWstBRUrRE20MQ0oCCgixqS+KZqQGL4AH4D4CQzREJuAqKQhJSGmGoOxJAikrG1t\nS1t2l2W77c7O087O3p251xetw7bU7qzxvLrn3nP/v3vOfchF5879Av+vUQD0xGO2DlY1vVJ9QgEA\niENATsMAEJ2acqieWl6+OTYOlIqi6AigiQoA4BzZOsy2xoYGSsj1az/HZpKOAIqcfRSX2ttbHQIA\noKtrV7GII70dwxe+o5SWAfS+8gLKywHeL0qqE/Ubo2Nzs/PL6aTL5To5eBwhVAYAAI07W/68M3P/\n3l/rhK7/VOo+TMRXG7quNLc1fjo0iNDaSSoPYBCK7On0+dyzs7GRkTXd6FS0NObixYsAcPXKKDFR\nc0tT6RBXFgAACKGXXu4ev31b0cXhS5fDoebSzEdHxvY933fp8g8fHD8CCG2cW+lF+/H7awzisvIK\nYkNel56V9dr6AMY4HG7f39fzdHz5Em2wI0cPyhmpqyvS2dqwfVv7vt5ugRc0SdxU/b9ksGYUUnFp\nZnJCCIW6ezvXPQ7rreIMVm1xcTG5oswtRjueawP6r+rw9CYvPDBlTeE4VpKzfp/f7/On02Lf/mZJ\nwXMzot9fNTs32d6xQ05rtQHOHayZnJnu7el2BBj99bEsPdrZ/Iyq5S3TdLtdlgUMwwg1/PSklhYl\nAsCZmd09PRNT05EdTYLg0icMPWtsnetaiW7eixVJwcDFZDpDLRIM8oqmZbJpUcoSSmLJRCqTLmBT\nKWBFLwJlWUK0nPbWgTeyapkbvpbB3HwylVgINbXmLVPKqZyiEFqs8Vf5vb4lScKmCQgwNtxeiEb/\nYF1V2DQlSbo7cWdo6BNHgOVUrKVtJ1CmUCwAsIZpFk1TMyS1YIBFTWJxnKcq4C3ktVB1TcAHiAFZ\nU/hqfovzsw4Q8GJZ0ayCruexO8h7WY5hwOPxYgvcHhfolACJJ+M1fFDBOLGUqltZUgqZjz88ubU6\n2HtwevCUh+MIJQzBTFExScHQZU0VFWVFzK5wHg4XcHVtnZjTJTFjAucLVO3Z01dWHUrvgQU0yNea\nucfdHa1g5FhAhiabBV2JT8zfHxPVnChmMcVeJisIbhPoro5wZQAGkKUlwu3bX9+/20XzFjFZhmEQ\neIVwy7ORep7xcNRITumGUdSNgf4DTtSfAH6/Pa1KqaZtwomj7wFAZvmhsjTJ+yx1eV7w6qfef1tV\nDJblOLfH7XZ/dOIdh+qwusm/jd96MJ/sf617V2cHAJw//2WkZ++hgTdLz8fngwPDV26EagPxRMK5\n+loGDfVhaWVpVR0Azp79AhhAlG4I9fsYXqg9ffqzigEziwtnzgzZXQghbBhXR65vCA0EqzVVDlT5\nKwYokmKvdrVx7PBB6uIIrEuirbXRsjam5QhgYMMut904MtA//M23paHhlma13MuzOSDo9246xtfU\nf3Xha9tFFHEsWzGAAOxobNp0rO/VF6t5wXYXYjFcdPrFs0vJAMDefZFNg+rr6o4fO2y7d+5Gg0He\nIcAuNYMASMlneAt791B/3njy2bZnlU6n//TY9jcs+CHXcbVvRgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F3241F53048>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}